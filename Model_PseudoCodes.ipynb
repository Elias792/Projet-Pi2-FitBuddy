{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import necessary libraries:\n",
    "   - FFT, Wavelet Transforms for repetition counting\n",
    "   - RNNs, LSTMs for phase speed analysis\n",
    "   - Threshold-based segmentation and Hidden Markov Models (HMM) for break time analysis\n",
    "   - XGBoost or CNNs for motion speed analysis\n",
    "\n",
    "2. Initialize and load models:\n",
    "   - Load pre-trained models for each task (ensure they are trained on similar data)\n",
    "\n",
    "3. Process accelerometer data for repetition counting & set timing:\n",
    "   FUNCTION process_repetitions(accel_data):\n",
    "       APPLY FFT or Wavelet Transform to accel_data\n",
    "       IDENTIFY peaks and valleys to determine repetitions and sets\n",
    "       RETURN repetitions, set_times\n",
    "\n",
    "4. Analyze phase speed using RNN or LSTM:\n",
    "   FUNCTION analyze_phase_speed(accel_data):\n",
    "       PREPROCESS data for RNN/LSTM (e.g., normalization, sequencing)\n",
    "       USE RNN/LSTM to predict phase speeds\n",
    "       RETURN phase_speeds\n",
    "\n",
    "5. Determine break times using threshold-based segmentation + HMM:\n",
    "   FUNCTION determine_break_times(set_times):\n",
    "       APPLY threshold-based segmentation to detect breaks between sets\n",
    "       USE HMM to refine and confirm break periods\n",
    "       RETURN break_times\n",
    "\n",
    "6. Analyze motion speed using XGBoost or CNN:\n",
    "   FUNCTION analyze_motion_speed(accel_data):\n",
    "       PREPROCESS data (feature extraction suitable for time-series)\n",
    "       APPLY XGBoost or train a CNN on the preprocessed data\n",
    "       PREDICT motion speeds for each movement phase\n",
    "       RETURN motion_speeds\n",
    "\n",
    "7. Main data processing loop:\n",
    "   FOR each data_point in accelerometer_data:\n",
    "       accel_data = collect_data(data_point)\n",
    "       repetitions, set_times = process_repetitions(accel_data)\n",
    "       phase_speeds = analyze_phase_speed(accel_data)\n",
    "       break_times = determine_break_times(set_times)\n",
    "       motion_speeds = analyze_motion_speed(accel_data)\n",
    "\n",
    "       PRINT \"Repetitions:\", repetitions\n",
    "       PRINT \"Set Times:\", set_times\n",
    "       PRINT \"Phase Speeds:\", phase_speeds\n",
    "       PRINT \"Break Times:\", break_times\n",
    "       PRINT \"Motion Speeds:\", motion_speeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repetition Counting and Set Timing with FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "# what FFT basically does is transforms frequency domain into time estimates, and its best for identifying frequency components while retaining time localization\n",
    "def process_repetitions(accel_data):\n",
    "    # Apply FFT\n",
    "    fft_result = np.fft.fft(accel_data)\n",
    "    frequencies = np.fft.fftfreq(len(accel_data))\n",
    "\n",
    "    # Identify peaks in the frequency domain\n",
    "    peaks = scipy.signal.find_peaks(np.abs(fft_result), height=0.5)  # threshold height as needed\n",
    "    peak_freqs = frequencies[peaks[0]]\n",
    "\n",
    "    # Convert frequencies to time to estimate repetitions\n",
    "    rep_times = 1 / peak_freqs\n",
    "\n",
    "    return len(peaks[0]), np.sum(rep_times)\n",
    "\n",
    "# Example usage\n",
    "# accel_data = read_accelerometer_data()\n",
    "# rep_count, set_times = process_repetitions(accel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Speed Analysis with RNNs (or maybe LSTMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# LSTMs are better with handling long term dependencies, which might be needed here while addressing the vanishing gradient problem in RNNs\n",
    "def analyze_phase_speed(accel_data, model_path='path_to_rnn_model.h5'):\n",
    "    # Load trained RNN model or untrained (trial and error process)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    processed_data = pad_sequences([accel_data], maxlen=100, dtype='float32', padding='post')  # adjust padding as needed\n",
    "\n",
    "    # Predict phase speeds\n",
    "    phase_speeds = model.predict(processed_data)\n",
    "\n",
    "    return phase_speeds.flatten()\n",
    "\n",
    "# Example usage\n",
    "# rnn_model_path = 'saved_rnn_model.h5'\n",
    "# phase_speeds = analyze_phase_speed(accel_data, rnn_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break Time Analysis with Threshold-based Segmentation and HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "def determine_break_times(accel_data, threshold=0.2):\n",
    "    # Segment data using threshold\n",
    "    is_break = accel_data < threshold\n",
    "    segments = np.diff(is_break.astype(int))\n",
    "\n",
    "    # Train and apply Hidden Markov Model, this model works based on probabilities\n",
    "    # this works better because it can handle short pauses and irregular breaks but needs a better training dataset\n",
    "    model = hmm.GaussianHMM(n_components=2)\n",
    "    model.fit(segments.reshape(-1, 1))\n",
    "\n",
    "    # Predict states\n",
    "    states = model.predict(segments.reshape(-1, 1))\n",
    "    break_times = np.where(states == 1)[0]\n",
    "\n",
    "    return break_times\n",
    "\n",
    "# Example usage\n",
    "# break_times = determine_break_times(accel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Speed Analysis with XGBoost or CNNs (Trial and Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost can handle non linear relationships and handles structured data well\n",
    "def analyze_motion_speed(accel_data, model_path='path_to_xgb_model.json'):\n",
    "    # Load trained XGBoost model\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.load_model(model_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    # Assume accel_data is preprocessed appropriately here\n",
    "\n",
    "    # Predict motion speeds\n",
    "    motion_speeds = model.predict(np.array([accel_data]))\n",
    "\n",
    "    return motion_speeds\n",
    "\n",
    "# Example usage\n",
    "# xgb_model_path = 'saved_xgb_model.json'\n",
    "# motion_speeds = analyze_motion_speed(accel_data, xgb_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USing CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# CNNs automatically extracts features and recognizes patterns, and is great at handling speed anomalies\n",
    "def analyze_motion_speed_with_cnn(accel_data, model_path='path_to_cnn_model.h5'):\n",
    "    # Load trained CNN model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Preprocess data (reshaping into the expected input shape for the CNN)\n",
    "    accel_data = accel_data.reshape((1, 28, 28, 1))  # Example reshaping, adjust as needed\n",
    "\n",
    "    # Predict motion speeds\n",
    "    motion_speeds = model.predict(accel_data)\n",
    "\n",
    "    return motion_speeds.flatten()\n",
    "\n",
    "# Example usage\n",
    "# cnn_model_path = 'saved_cnn_model.h5'\n",
    "# motion_speeds = analyze_motion_speed_with_cnn(accel_data, cnn_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Machine Usage:\n",
    "### K-Means Clustering:\n",
    "\n",
    "- Unsupervised learning approach, ie: no need for labeled data\n",
    "- can handle high volume sensor data, in fact thrives by it\n",
    "- groups machines based on similar usage trends"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
